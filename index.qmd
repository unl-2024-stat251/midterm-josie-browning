---
title: 251 Midterm Exam
author: Josie Browning
date: '2024-03-07'
execute:
  error: false
categories:
- Exam
- Week07
editor: 
  markdown: 
    wrap: sentence
---

In this exam, you'll be using data collected about US polling places.
The [Center for Public Integrity](https://publicintegrity.org/) assembled this data using open records requests and contact with state or county election officials.
Full documentation is available on the [github repository for the data](https://github.com/PublicI/us-polling-places) - each state's details can be found in a README file for that state; there is also a machine-readable `manifest.yaml` file for each state provided.

We will start out by using data assembled by the TidyTuesday project, but will eventually get to the raw data as well.

The raw CSV data is available at https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2024/2024-01-16/polling_places.csv

```{r r-setup, message=FALSE, warning=FALSE}
# load any R packages you use in this chunk
library(dplyr)
library(ggplot2)
library(tidyr)
```

# Data Input - Polling Places

(30 pts)

## Data File Inspection

Here are the first six lines of the TidyTuesday CSV file:

```         
election_date,state,county_name,jurisdiction,jurisdiction_type,precinct_id,precinct_name,polling_place_id,location_type,name,address,notes,source,source_date,source_notes
2020-11-03,AL,AUTAUGA,AUTAUGA,county,NA,AUTAUGAVILLE VOL FIRE DEPT,NA,election_day,AUTAUGAVILLE VOL FIRE DEPT,"2610 HIGHWAY 14 W, AUTAUGAVILLE, AL 36003",NA,ORR,2020-10-21,NA
2020-11-03,AL,AUTAUGA,AUTAUGA,county,NA,BILLINGSLEY COMMUNITY CENTER,NA,election_day,BILLINGSLEY COMMUNITY CENTER,"2159 COUNTY RD 37, BILLINGSLEY, AL 36006",NA,ORR,2020-10-21,NA
2020-11-03,AL,AUTAUGA,AUTAUGA,county,NA,BOONE'S CHAPEL,NA,election_day,BOONE'S CHAPEL,"2301 COUNTY RD 66, PRATTVILLE, AL 36067",NA,ORR,2020-10-21,NA
2020-11-03,AL,AUTAUGA,AUTAUGA,county,NA,BOOTH VOL FIRE DEPT,NA,election_day,BOOTH VOL FIRE DEPT,"1701 COUNTY ROAD 10, BOOTH, AL 36008",NA,ORR,2020-10-21,NA
2020-11-03,AL,AUTAUGA,AUTAUGA,county,NA,CAMELLIA BAPTIST CH,NA,election_day,CAMELLIA BAPTIST CH,"201 WOODVALE ROAD, PRATTVILLE, AL 36067",NA,ORR,2020-10-21,NA
```

1.  What is the file delimiter?
    (1 pt)\
    The file delimiter for this data is a comma.

2.  What is the header?
    (1 pt)\
    The header of this file is the first row (election_date, state, county_name...)

3.  How many columns will the data have when it is read in using R or Python?
    (1 pt)\
    This data will have 15 columns.

4.  How is the data stored differently in the address field compared to the name field (1 pt), and why is this different handling necessary (1 pt)?\
    The name field has data in it that's stored very simply, just a couple of words.
    The address column almost always has numbers, punctuation, and words.
    Dealing with the address column is more difficult to deal with and requires us to extract fractions of the address to use in data.

## Reading the Data

Read in the data in R (5 pts) and in python (5 pts).

Make sure to load any packages which are necessary to run your code in the setup chunks at the beginning of the document.

```{r r-read-data}
polling <- read.csv("https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2024/2024-01-16/polling_places.csv")
```

```{python py-read-data}
import pandas as pd
polling = pd.read_csv("https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2024/2024-01-16/polling_places.csv", low_memory = False)

# I used low_memory to dismiss the warning that some columns had different data types
```

## Summarize the Data

Using any method you choose from either language, fill in the following table.

Language used: R

Make sure your terms match the language you're using and the code you provided above.
If you use code to get these values (which is probably a good idea), please use the code chunks provided here:

```{r r-data-summary-code}
#this is creating a dataframe that reads the class type for each variable/column
data.frame(sapply(polling, class))

#I wrote this for loop to take each variable and count the number of na's in that variable 
for (i in colnames(polling)) {
  na_count <- sum(is.na(polling[i]))
  print(na_count)
}

#this is creating a numeric vector that contains the number of variables in polling
unique_count <- as.numeric(ncol(polling))

#this loop takes each value in the sequence created and counts the number of unique values
for (i in seq_along(polling)) {
  unique_count[i] <- count(unique(na.omit(polling[i])))
}
unique_count
```

When computing the number of unique values, exclude missing values.

| Column Name       | Data Type (5 pts) | \# missing values (5 pts) | \# unique values (5 pts) |
|------------------|------------------|------------------|------------------|
| election_date     | character         | 0                         | 7                        |
| state             | character         | 0                         | 39                       |
| county_name       | character         | 114,568                   | 1,880                    |
| jurisdiction      | character         | 103,599                   | 9,206                    |
| jurisdiction_type | character         | 60                        | 7                        |
| precinct_id       | character         | 148,834                   | 50,287                   |
| precinct_name     | character         | 96,860                    | 110,887                  |
| polling_place_id  | character         | 409,178                   | 11,145                   |
| location_type     | character         | 192,820                   | 6                        |
| name              | character         | 75                        | 105,985                  |
| address           | character         | 2,996                     | 151,319                  |
| notes             | character         | 416,312                   | 9,614                    |
| source            | character         | 0                         | 4                        |
| source_date       | character         | 0                         | 36                       |
| source_notes      | character         | 425,353                   | 4                        |

: Summary of Polling Data

# Data Cleaning - Polling Places over Time

(50 pts)

For this part of the exam, you'll use your student ID to get the state you'll be working with.

```{r student-id-state-assign}
my_nuid <- 13388084
state_ids <- readRDS("state-ids.RDS")
my_state <- state_ids$state[my_nuid%%37]
print(my_state)

#CA only has data for one year, I will use NE instead
```

Your end goal is to get a plot of the number of available polling places in each election, with separate lines for each jurisdiction (e.g. county) within your state.

## Steps

(10 pts)

Write out the steps (in plain language) required to get from the polling place data provided [here](https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2024/2024-01-16/polling_places.csv) to the data you need to create your plot.
Make sure to remove polling places which do not make sense - e.g. those with an address consisting of just the state name, or those named "DO NOT USE".

For each step, identify the data manipulation verb you will use, and any variables you will pass in as arguments.
Fill in the following table when you are finished.
Add new rows by moving to a new line, and separate each cell in the table with `|` (spaces matter).
`|` is on the key above the enter key and shares a key with `\` (backslash).
You will need to hold shift down.

| Step \# | Verb      | Arguments                                                                         |
|------------------|------------------|------------------------------------|
| 1       | filter    | remove any names that are "Do not use"                                            |
| 2       | filter    | include only observations that include the state NE                               |
| 3       | group by  | group together the county names and the election dates                            |
| 4       | summarise | add a column that counts all the polling places per county for that election year |

## Code

(10 pts)

Write code in R or python to execute the steps you outlined above.

```{r}
#I created a new dataframe by filtering only the observations with CA in the state column, 
#and also filtered out any polling locations named "DO NOT USE"
polling_NE <- polling %>%
  filter(name !="DO NOT USE") %>%
  filter(state == "NE")

polling_NE <- polling_NE %>%
  group_by(county_name, election_date) %>%
  summarise(polling_places = n(), .groups = "drop")

#I used the .groups arguement to override the summarise fucntion grouping output by county_name
```

## Chart Description

(7 pts)

Use the grammar of graphics to identify the components of the chart here, which provides the data for Wisconsin.
![Wisconsin counties where the number of polling places changed, 2012-2020](wisconsin-example.jpg){width="50%"}

-   geom: geom_line

-   aesthetics: (list at least 3)

    -   x = election_year

    -   y = polling_places (this is a variable I created with summarise(polling_places = n())

    -   group = county_name

-   coordinate system: Cartesian

-   y axis scale: continuous, range: 0 to 570, scale is wider between 0 and 100, but much tighter from 100 to 570

-   x axis scale: discrete, range: 2012 to 2020, by 2 years

## Chart

(20 pts)

Write code in R or python to create a chart like that shown at the beginning of this example (5 pts).
Make sure your axes are labeled (5 pts) and your chart has a title (5 pts).
Include your plot in this document and make sure you have a figure caption that describes what someone should notice in the chart (5 pts) You may do this either by modifying the chunk options or by using `include=F` and manually including the picture with a caption.

```{r, fig.cap = "Graph of Nebraska Polling Place Numbers For Each County Over Time"}
ggplot(polling_NE, aes(x = election_date, y = polling_places, group = county_name)) +
  geom_line() +
  labs(title = "Nebraska Polling Place Changes, 2012-2020", 
       x = "Year", 
       y = "Number of Polling Places per County")+
  scale_y_continuous(breaks = c(10, 50, 100, 200), trans = "sqrt") +
  scale_x_discrete(labels = c(2012, 2014, 2016, 2018, 2020))
```

## Modifications

Evaluate the chart you created for comprehensibility and accessibility.
(1 pt)

I think this chart is not very comprehensible, mostly due to the large amount of data we are trying to show in one graph.
A lot of the lines are very close together and it is difficult to see how they change or estimate the count the lines are at.

What modifications might you add to this chart to make it clearer and more understandable?
(2 pts)

I think I would start by further altering the y scale so we can try to estimate the numbers of the lines more easily and accurately.
I also think it may be a good idea to group together counties by population.
It would reduce the number of lines on the graph and get a more understandable perspective of our data.
This way we could also add a legend and use color to visually see the changes over time more easily.

# Data Processing

(20 pts)

You want to mail a letter to every polling place in the state you were assigned.
In order to do this, you need to separate out the pieces of the address: building number, street, city, state, and zip code.
Note that not all addresses will have all of these components - in Alaska, for example, there are often not street numbers or even names.

## Function Steps

(5 pts)

Use the following addresses to think through the steps you will need to accomplish this task.

```         
Tatitlek, AK 99677
First Street, Cordova, AK 99574
105 ICE ST, MENASHA, WI 54952-3223
1025 W 5TH AVE, OSHKOSH, WI 54902
1702 COUNTY ROAD 40 W, PRATTVILLE, AL 36067
5281 HIGHWAY 29, CORINTH VFD (PEROTE STATION), BANKS, AL 36005
713 W. MOUNTAIN AVENUE, JACKSONVILLE, AL 36265
COMMUNITY CENTER, 1168 HWY 84, SILAS, AL 36919
```

Write out the steps your function will need to accomplish in plain language.

1.  Filter the data frame to only have the relevant columns

2.  Separate the addresses into four section: street, city, state, and zip code.

    1.  Separate street and city from state and zip by a comma

    2.  Separate state and zip by a space

3.  Ensure that missing pieces produce an NA in the corresponding column

## Function Code - Single Address

(5 pts)

Write a function, `address_parser`, which can handle a single address and return a data structure containing each piece of the address, with NAs for pieces which are not matched.

(change this chunk to python if you'd prefer to use python over R for this task)

```{r single-address-parser}
#street, city, state, number

polling_ad <- polling %>%
  select(address)

address_parser <- function(polling_ad){
  polling_ad <- data.frame(address = polling_ad)
    parsed <- separate(polling_ad, address, into = 
                  c("street", "city", "state_zip"), sep = ",\\s*", convert = TRUE)
    parsed <- separate(parsed, state_zip, into = 
                  c("state", "zip code"), sep = " ", convert = TRUE)
  return(parsed)
}

address_parser("123 Main St, Lincoln, Ne 68508")
```

This chunk will test your function on the addresses provided as examples.
(change this chunk to python if you used python above)

```{r single-address-parser-test, error = T}
address_parser("Tatitlek, AK 99677")
address_parser("First Street, Cordova, AK 99574")
address_parser("105 ICE ST, MENASHA, WI 54952-3223")
address_parser("1025 W 5TH AVE, OSHKOSH, WI 54902")
address_parser("1702 COUNTY ROAD 40 W, PRATTVILLE, AL 36067")
address_parser("5281 HIGHWAY 29, CORINTH VFD (PEROTE STATION), BANKS, AL 36005")
address_parser("713 W. MOUNTAIN AVENUE, JACKSONVILLE, AL 36265")
address_parser("COMMUNITY CENTER, 1168 HWY 84, SILAS, AL 36919")
```

## Function Code - Vector

(5 pts)

Write a function, `address_vec`, which can parse a vector of addresses and return a data frame with columns corresponding to each piece of the address.

(change this chunk to python if you'd prefer to use python over R for this task)

```{r vector-address-parser}
polling_vec <- as.vector(polling["address"])

address_vec <- function(polling_vec) {
  parsed <- separate(data.frame(address = polling_vec), address, into = 
                c("street", "city", "state_zip"), sep = ",\\s*", convert = TRUE)
  parsed <- separate(parsed, state_zip, into = 
                c("state", "zip code"), sep = " ", convert = TRUE)
  return(parsed)
}
address_vec("123 Main St, Lincoln, Ne 68508")
```

This chunk will test your function on the addresses provided as examples.
Delete whichever chunk corresponds to the language you didn't use.

```{r r-vector-address-parser-test, error = T}
test_vec <- c("Tatitlek, AK 99677", "First Street, Cordova, AK 99574", "105 ICE ST, MENASHA, WI 54952-3223", "1025 W 5TH AVE, OSHKOSH, WI 54902", "1702 COUNTY ROAD 40 W, PRATTVILLE, AL 36067", "5281 HIGHWAY 29, CORINTH VFD (PEROTE STATION), BANKS, AL 36005", "713 W. MOUNTAIN AVENUE, JACKSONVILLE, AL 36265", "COMMUNITY CENTER, 1168 HWY 84, SILAS, AL 36919")
address_vec(test_vec)
```

## Function Evaluation

Use your function to parse a vector of the unique polling place addresses in your state, creating a data table of address components for your letters.
(5 pts)

```{r r-function-eval, max.print=10, warning=FALSE}
ne_addresses <- polling %>%
  filter(name !="DO NOT USE") %>%
  filter(state == "NE") %>%
  filter(address !="NE") %>%
  select(address)

ne_addresses_vec <- c(ne_addresses)
```

```{r R.options=list(max.print=60), warning=FALSE}
address_vec(ne_addresses_vec)
```

Where did your function have issues, if it did?
(5 pts)

After working on the function for awhile, I know where the main faults in my function are.
The function will work fine for any address that is fully intact and following a standard format.
If the address as additional pieces, the function has a difficult time separating the address correctly. The function also has a hard time correctly placing the NA if a piece is missing.
I believe that the function separate() is not the best way to handle this, and there is likely another layer to the function that would need to be added to handle these irregular addresses.
I would also consider writing a for loop to transform irregular addresses into a format that the address_parser function can handle.
